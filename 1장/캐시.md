

## 캐시

- 캐시는 값비싼 연산 결과 또는 자주 참조되는 데이터를 메모리 안에 두고,  
  뒤이은 요청이 보다 빨리 처리될 수 있도록 하는 저장소임  
  
- 그림 1-6에서 살펴본 바와 같이, 웹 페이지를 새로고침 할 때마다  
  표시할 데이터를 가져오기 위해 한 번 이상의 데이터베이스 호출이 발생함  
  
- 애플리케이션의 성능은 데이터베이스를 얼마나 자주 호출하느냐에 크게 좌우되는데,  
  캐시는 그런 문제를 완화할 수 있음  
  

### 캐시 계층  

- 캐시 계층(cache tier)는 데이터가 잠시 보관되는 곳으로  
  데이터베이스보다 훨씬 빠름  
  별도의 캐시 계층을 두면 성능이 개선될 뿐 아니라  
  데이터베이스의 부하를 줄일 수 있고,  
  캐시 계층의 규모를 독립적으로 확장시키는 것도 가능해짐  
  
 
 - 요청을 받은 웹 서버는 캐시에 응답이 저장되어 있는지를 봄
   만일 저장되어 있다면 해당 데이터를 클라이언트에 반환함  
   없는 경우에는 데이터베이스 질의를 통해 데이터를 찾아 캐시에 저장한 뒤 클라이언트에 반환함  
   이러한 캐시 전략을 읽기 주도형 캐시 전략(read-through caching strategy)라고 부름  
   
 - 이것 이외에도 다양한 캐시 전략이 있는데, 캐시할 데이터 종류, 크기 액세스 패턴에 맞는 캐시 전략을 선택하면 됨.  

 - 캐시 서버를 이용하는 방법은 간단한데 대부분의 캐시 서버들이 일반적으로 널리 쓰이는 프로그래밍 언어로 API를 제공하기 때문임
   다음 쪽 코드는 memcached API의 전형적 사용 예임
   
 ```
 SECONDS = 1
 cache.set('myKey', 'hi there', 3600*SECONDS);
 cache.get('myKey');
 ```
 
 
 ### 캐시 사용 시 유의할 점
 
 - 캐시를 사용할 때는 아래 사항들을 고려하여야 함  

 (1) 캐시는 어떤 상황에 바람직한가? 데이터 갱신은 자주 일어나지 않지만, 참조는 빈번하게 일어난다면 고려해볼만 함  
 
 (2) 어떤 데이터를 캐시에 두어야 하는가? 캐시는 데이터를 휘발성 메모리에 두므로,     
     영속적으로 보관할 데이터를 캐시에 두는 것은 바람직하지 않음     
     예를 들어, 캐시 서버가 재시작되면 캐시 내의 모든 데이터는 사라짐    
     중요 데이터는 여전히 지속적 저장소(persistent data store)에 두어야 함   
     
 (3) 캐시에 보관된 데이터는 어떻게 만료(expire)되는가?   
     이에 대한 정책을 마련해 두는 것은 좋은 습관임    
     만료된 데이터는 캐시에서 삭제되어야 함    
     만료 정책이 없으면 데이터는 캐시에 계속 남게됨    
     만료 기한은 너무 짧으면 곤란한데, 데이터베이스를 너무 자주 읽게 될 것이기 때문임    
     너무 길어도 곤란한데, 원본과 차이가 날 가능성이 높아지기 때문임    
     
 (4) 일관성(consistency)은 어떻게 유지되는가? 일관성은 데이터 저장소의 원본과 캐시 내의 사본이 같은지 여부임.    
     저장소의 원본을 갱신하는 연산과 캐시를 갱신하는 연산이 단일 트랜잭션으로 처리되지 않는 경우    
     이 일관성은 깨질 수 있음    
     여러 지역에 걸쳐 시스템을 확장해 나가는 경우 캐시와 저장소 사이의 일관성을 유지하는 것은 어려운 문제가 됨.    
     
 (5) 장애에는 어떻게 대처할 것인가? 캐시 서버를 한 대만 두는 경우 해당 서버는    
     단일 장애 지점(SPOF, Single Point Of Failure)이 되어버릴 가능성이 있음    
     위키피디아에 따르면 단일 장애 지점의 정의는 다음과 같음    
     "어떤 특정 지점에서의 장애가 전체 시스템의 동작을 중단시켜버릴 수 있는 경우,    
      우리는 해당 지점을 단일 장애 지점이라고 부름"    
     결과적으로, SPOF를 피하려면 여러 지역에 걸쳐 캐시 서버를 분산시켜야 함.    
     
 (6) 캐시 메모리는 얼마나 크게 잡을 것인가? 캐시 메모리가 너무 작으면 액세스 패턴에 따라서는   
     데이터가 너무 자주 캐시에서 밀려나버려 캐시의 성능이 떨어지게 됨.    
     이를 막을 한 가지 방법은 캐시 메모리를 과할당하는 것임    
     이렇게 하면 캐시에 보관될 데이터가 갑자기 늘어났을 때 생길 문제도 방지할 수 있게 됨 
     
 (7) 데이터 방출(eviction) 정책은 무엇인가?     
     캐시가 꽉 차버리면 추가로 캐시에 데이터를 넣어야 할 경우 기존 데이터를 내보내야 함    
     이것을 캐시 데이터 방출 정책이라 함.    
     그 가운데 가장 널리 쓰이는 것은 LRU(Least Recently Used) 임    
     다른 정책으로는 LFU나 FIFO 같은 것도 있으며,    
     경우에 맞게 적용 가능함.  
     
     
 ### 무상태(stateless) 웹 계층
 
 - 이제 웹 계층을 수평적으로 확장하는 방법을 고민해 볼 순서임    
   이를 위해서는 상태 정보(사용자 세션 데이터와 같은)를 웹 계층에서 제거해야 함    
   바람직한 전략은 상태 정보를 관계형 데이터베이스나 NoSQL 같은 지속성 저장소에 보관하고,    
   필요할 때 가져오도록 하는 것임    
   이렇게 구성된 웹 계층을 무상태 웹 계층이라 부름    
   
   
### 상태 정보 의존적인 아키텍쳐  

- 상태 정보를 보관하는 서버와 그렇지 않은 서버 사이에는 몇 가지 중요한 차이가 있음.    
  상태 정보를 보관하는 서버는 클라이언트 정보,  
  즉 상태를 유지하여 요청들 사이에 공유되도록 함.  
  무상태 서버에는 이런 장치가 없음  
  
- 그림 1-12에서 사용자 A의 세션 정보나 프로파일 이미지 같은 상태 정보는 서버1에 저장됨  
  사용자 A를 인증하기 위해 HTTP 요청은 반드시 서버 1로 전송되어야 함.  
  요청이 서버 2로 전송되면 인증은 실패할 것인데,  
  서버 2에 사용자 A에 관한 데이터는 보관되어 있지 않기 때문임.  
  마찬가지로, 사용자 B로부터의 HTTP 요청은 전부 서버 2로 전송되어야 하고,  
  사용자 C로부터의 HTTP 요청은 전부 서버 3으로 전송되어야 함.  
  
- 문제는 같은 클라이언트로부터의 요청은 항상 같은 서버로 전송되어야 한다는 것임  
  대부분의 로드밸런서가 이를 지원하기 위해 고정 세션이라는 기능을 제공함  
  이는 로드밸런서에 부담을 줌   
  게다가 로드밸런서 뒷단에 서버를 추가하거나 제거하기도 까다로워짐.  
  이들 서버의 장애를 처리하기도 복잡해짐.  
  

### 무상태 아키텍쳐

- 이 구조에서 사용자로부터의 HTTP 요청은 어떤 웹 서버로도 전달될 수 있음.  
  웹 서버는 상태 정보가 필요할 경우 공유 저장소로부터 데이터를 가져옴.  
  따라서 상태 정보는 웹 서버로부터 물리적으로 분리되어 있음.  
  이런 구조는 단순하고, 안정적이며, 규모 확장이 쉬움.  
  
  
- 그림 1-14에서 우리는 세션 데이터를 웹 계층에서 분리하고,  
  지속성 데이터 보관소에 저장하도록 만듦.  
  이 공유 저장소는 관계형 데이터베이스일 수도 있고,  
  Memcached/Redis 같은 캐시 시스템일 수도 있고, NoSQL일 수도 있음. 
  여기서는 NoSQL을 사용하였는데, 규모 확장이 간편해서임.  
  
- 자동 규모 확장(autoscaling)은 트래픽 양에 따라  
  웹 서버를 자동으로 추가하거나 삭제하는 기능을 뜻함.  
  상태 정보가 웹 서버들로부터 제거되었으므로,  
  트래픽 양에 따라 웹 서버를 넣거나 빼기만 하면 자동으로 규모를 확장할 수 있게 됨.  
  
  

### 데이터 센터

- 장애가 없는 상황에서 사용자는 가장 가까운 데이터 센터로 안내됨  
  통상 이 절차를 지리적 라우팅이라고 부름.  
  지리적 라우팅에서의 geoDNS는 사용자의 위치에 따라 도메인 이름을 어떤 IP 주소로  
  변환할지 결정할 수 있도록 해주는 DNS 서비스임.  
  그 결과로 x% 사용자는 US-East 센터로, (100-x)%의 사용자는 US-West 센터로 안내됨.  
  
- 이들 데이터 센터 중 하나에 심각한 장애가 발생하면 모든 트래픽은 장애가 없는 데이터 센터로 전송됨.  
  그림 1-16은 데이터 센터2(US-West)에 장애가 발생하여,  
  모든 트래픽이 데이터센터1(US-East)로 전송되는 상황을 보여줌.  
  
- 이 사례와 같은 다중 데이터센터 아키텍쳐를 만들려면 몇 가지 기술적 난제를 해결해야 함.  

  (1) 트래픽 우회: 올바른 데이터 센터로 트래픽을 보내는 효과적인 방법을 찾아야 함.  
                   GeoDNS는 사용자에게서 가장 가까운 데이터센터로 트래픽을 보낼 수 있도록 해줌. 
  (2) 데이터 동기화(synchronization): 데이터 센터마다 별도의 데이터베이스를 사용하고 있는 상황이라면,  
                                      장애가 자동으로 복구되어(failover) 트래픽이 다른 데이터베이스로 우회된다 해도,  
                                      해당 데이터센터에는 찾는 데이터가 없을 수 있음.  
  (3) 테스트와 배포(deployment): 여러 데이터 센터를 사용하도록 시스템이 구성된 상황이라면,  
                                 웹 사이트 또는 애플리케이션을 여러 위치에서 테스트해 보는 것이 중요함.  
                                 한편, 자동화된 배포 도구는 모든 데이터 센터에 동일한 서비스가 설치되도록 하는데 중요한 역할을 함.  



### 메시지 큐

- 메시지 큐는 메시지의 무손실(durability, 즉 메시지 큐에 일단 보관된 메시지는 소비자가 꺼낼 때까지 안전히 보관된다는 특성)  
  을 보장하는 비동기 통신을 지원하는 컴포넌트임.  
  메시지의 버퍼 역할을 하며, 비동기적으로 전송함.  
  메시지 큐의 기본 아키텍쳐는 간단함. 생산자 또는 발행자라고 불리는 입력 서비스가 메시지를 만들어 메시지 큐에 발행함.  
    
- 큐에는 보통 소비자 혹은 구독자라 불리는 서비스 혹은 서버가 연결되어 있는데,  
  메시지를 받아 그에 맞는 동작을 수행하는 역할을 함.  
  
 
### 로그, 메트릭, 자동화

- 몇 개 서버에서 실행되는 소규모 웹 사이트를 만들 때는 로그나 메트릭, 자동화 같은 것은 하면 좋지만 꼭 할 필요는 없었음.  
  하지만 일단 웹사이트와 함께 사업 규모가 커지고 나면, 그런 도구에 필수적으로 투자해야 함.  
  
(1) 로그
- 에러 로그를 모니터링하는 것은 중요함. 시스템의 오류와 문제들을 보다 쉽게 찾아낼 수 있도록 하기 때문임.  
  에러 로그는 서버 단위로 모니터링 할 수도 있지만, 로그를 단일 서비스로 모아주는 도구를 활용하면  
  더 편리하게 검색하고 조회할 수 있음  
  
(2) 메트릭
- 메트릭을 잘 수집하면 사업 현황에 관한 유용한 정보를 얻을 수도 있고,  
  시스템의 현재 상태를 손쉽게 파악할 수도 있음  
  메트릭 가운데 특히 유용한 것을 몇 가지 살펴보면 다음과 같음.  
  
(3) 자동화  
- 시스템이 크고 복잡해지면 생산성을 높이기 위해 자동화 도구를 활용해야 함.  
  
  


   

  
 
  
  
  
  
